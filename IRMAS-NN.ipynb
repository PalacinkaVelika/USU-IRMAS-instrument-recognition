{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import stft\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nahrání signálu\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEZAPOMENOUT ŘEŠIT OBA KANÁLY\n",
    "\n",
    "class Instrument:\n",
    "    def __init__(self, name, directory) -> None:\n",
    "        self.name = name\n",
    "        self.directory = directory\n",
    "        self.wav_files = [file for file in os.listdir(directory) if file.endswith('.wav')]\n",
    "        self.signals_raw = {}\n",
    "        self.signals_envelope = {}\n",
    "        self.signals_spectogram = {}\n",
    "        self._load_signals()\n",
    "\n",
    "    def _load_signals(self):\n",
    "        for wav_file in self.wav_files:\n",
    "            file_path = os.path.join(self.directory, wav_file)\n",
    "            sample_rate, data = wavfile.read(file_path)\n",
    "            self.signals_raw[wav_file] = (sample_rate, data) # Store the sample rate and signal data as a tuple (sample_rate, data)\n",
    "    \n",
    "\n",
    "all_instrument_classes = []\n",
    "\n",
    "all_instrument_classes.append(Instrument(\"cello\", \"Dataset\\\\cel\"))\n",
    "all_instrument_classes.append(Instrument(\"clarinet\", \"Dataset\\\\cla\"))\n",
    "all_instrument_classes.append(Instrument(\"flute\", \"Dataset\\\\flu\"))\n",
    "all_instrument_classes.append(Instrument(\"guitar_acoustic\", \"Dataset\\\\gac\"))\n",
    "all_instrument_classes.append(Instrument(\"guitar_electric\", \"Dataset\\\\gel\"))\n",
    "all_instrument_classes.append(Instrument(\"organ\", \"Dataset\\\\org\"))\n",
    "all_instrument_classes.append(Instrument(\"piano\", \"Dataset\\\\pia\"))\n",
    "all_instrument_classes.append(Instrument(\"saxophone\", \"Dataset\\\\sax\"))\n",
    "all_instrument_classes.append(Instrument(\"trumpet\", \"Dataset\\\\tru\"))\n",
    "all_instrument_classes.append(Instrument(\"violin\", \"Dataset\\\\vio\"))\n",
    "all_instrument_classes.append(Instrument(\"voice\", \"Dataset\\\\voi\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Očištění a sjednocení signálu\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEZAPOMENOUT ŘEŠIT OBA KANÁLY\n",
    "\n",
    "# Sjednocení\n",
    "## Všechna trénovací data mají stejný sample_rate(44100) i délku(3s) i data_shape(132299, 2), takže není třeba sjednocovat.\n",
    "\n",
    "# Očištění\n",
    "# Audio je kvalitní a žádné závažné problémy, které by bylo třeba odstranit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude envelope\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\popa4\\AppData\\Local\\Temp\\ipykernel_11932\\1640000231.py:7: RuntimeWarning: invalid value encountered in sqrt\n",
      "  rms = np.sqrt(np.mean(window**2)) if len(window) > 0 else 0\n"
     ]
    }
   ],
   "source": [
    "# RMS (Root Mean Square) Envelope, because i found it is best for continuous sounds (instruments)\n",
    "def amplitude_envelope(signal, sample_rate, window_size=0.05):\n",
    "    window_size_in_samples = int(window_size * sample_rate)\n",
    "    envelope = []\n",
    "    for i in range(0, len(signal), window_size_in_samples):\n",
    "        window = signal[i:i + window_size_in_samples]\n",
    "        rms = np.sqrt(np.mean(window**2)) if len(window) > 0 else 0\n",
    "        envelope.append(rms)\n",
    "    return np.array(envelope)\n",
    "\n",
    "\n",
    "for instrument in all_instrument_classes:\n",
    "    for wav_file, (sample_rate, signal) in instrument.signals_raw.items():\n",
    "        instrument.signals_envelope[wav_file] = amplitude_envelope(signal, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\popa4\\OneDrive\\Dokumenty\\GitHub\\USU-IRMAS-instrument-recognition\\.venv\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:1240: UserWarning: nperseg = 1024 is greater than input length  = 2, using nperseg = 2\n",
      "  freqs, time, Zxx = _spectral_helper(x, x, fs, window, nperseg, noverlap,\n"
     ]
    }
   ],
   "source": [
    "# spectrogram se počítá skrz sFT (frekvence místo amplitudy, neural network mňamuje)\n",
    "'''\n",
    "Přes librosu to nejde, divný dependencies na starší verze numpy + mel spectogram vzdávám, blbne to\n",
    "'''\n",
    "\n",
    "def create_spectrogram(signal, sample_rate, nperseg=1024):\n",
    "    frequencies, times, spectrogram = stft(signal, fs=sample_rate, nperseg=nperseg)\n",
    "    return np.abs(spectrogram)\n",
    "\n",
    "for instrument in all_instrument_classes:\n",
    "    for wav_file, (sample_rate, signal) in instrument.signals_raw.items():\n",
    "        instrument.signals_spectogram[wav_file] = create_spectrogram(signal, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 82.  30.   0.]\n",
      "  [ 82.  30.   0.]]\n",
      "\n",
      " [[ 73.  40.   0.]\n",
      "  [ 73.  40.   0.]]\n",
      "\n",
      " [[ 62.  49.   0.]\n",
      "  [ 62.  49.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[100. 141.   0.]\n",
      "  [100. 141.   0.]]\n",
      "\n",
      " [[ 89. 153.   0.]\n",
      "  [ 89. 153.   0.]]\n",
      "\n",
      " [[ 78. 163.   0.]\n",
      "  [ 78. 163.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "# x_train = signal\n",
    "# y_train = instrument\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(units=32, activation='Leaky ReLU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
