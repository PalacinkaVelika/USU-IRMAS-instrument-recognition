{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nahrání signálu\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEZAPOMENOUT ŘEŠIT OBA KANÁLY\n",
    "\n",
    "class Instrument:\n",
    "    def __init__(self, name, directory) -> None:\n",
    "        self.name = name\n",
    "        self.directory = directory\n",
    "        self.wav_files = [file for file in os.listdir(directory) if file.endswith('.wav')]\n",
    "        self.signals_raw = {}\n",
    "        self.signals_envelope = {}\n",
    "        self.signals_spectogram = {}\n",
    "        self._load_signals()\n",
    "\n",
    "    def _load_signals(self):\n",
    "        for wav_file in self.wav_files:\n",
    "            file_path = os.path.join(self.directory, wav_file)\n",
    "            sample_rate, data = wavfile.read(file_path)\n",
    "            self.signals_raw[wav_file] = (sample_rate, data) # Store the sample rate and signal data as a tuple (sample_rate, data)\n",
    "    \n",
    "\n",
    "all_instrument_classes = []\n",
    "\n",
    "all_instrument_classes.append(Instrument(\"cello\", \"Dataset\\\\cel\"))\n",
    "all_instrument_classes.append(Instrument(\"clarinet\", \"Dataset\\\\cla\"))\n",
    "all_instrument_classes.append(Instrument(\"flute\", \"Dataset\\\\flu\"))\n",
    "all_instrument_classes.append(Instrument(\"guitar_acoustic\", \"Dataset\\\\gac\"))\n",
    "all_instrument_classes.append(Instrument(\"guitar_electric\", \"Dataset\\\\gel\"))\n",
    "all_instrument_classes.append(Instrument(\"organ\", \"Dataset\\\\org\"))\n",
    "all_instrument_classes.append(Instrument(\"piano\", \"Dataset\\\\pia\"))\n",
    "all_instrument_classes.append(Instrument(\"saxophone\", \"Dataset\\\\sax\"))\n",
    "all_instrument_classes.append(Instrument(\"trumpet\", \"Dataset\\\\tru\"))\n",
    "all_instrument_classes.append(Instrument(\"violin\", \"Dataset\\\\vio\"))\n",
    "all_instrument_classes.append(Instrument(\"voice\", \"Dataset\\\\voi\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Očištění a sjednocení signálu\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEZAPOMENOUT ŘEŠIT OBA KANÁLY\n",
    "\n",
    "# Sjednocení\n",
    "## Všechna trénovací data mají stejný sample_rate(44100) i délku(3s) i data_shape(132299, 2), takže není třeba sjednocovat.\n",
    "\n",
    "# Očištění\n",
    "# Audio je kvalitní a žádné závažné problémy, které by bylo třeba odstranit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude envelope\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\popa4\\AppData\\Local\\Temp\\ipykernel_14188\\2639312768.py:7: RuntimeWarning: invalid value encountered in sqrt\n",
      "  rms = np.sqrt(np.mean(window**2)) if len(window) > 0 else 0  # Avoid errors with empty windows\n"
     ]
    }
   ],
   "source": [
    "# RMS (Root Mean Square) Envelope, because i found it is best for continuous sounds (instruments)\n",
    "def amplitude_envelope(signal, sample_rate, window_size=0.05):\n",
    "    window_size_in_samples = int(window_size * sample_rate)\n",
    "    envelope = []\n",
    "    for i in range(0, len(signal), window_size_in_samples):\n",
    "        window = signal[i:i + window_size_in_samples]\n",
    "        rms = np.sqrt(np.mean(window**2)) if len(window) > 0 else 0\n",
    "        envelope.append(rms)\n",
    "    return np.array(envelope)\n",
    "\n",
    "\n",
    "for instrument in all_instrument_classes:\n",
    "    for wav_file, (sample_rate, signal) in instrument.signals_raw.items():\n",
    "        instrument.signals_envelope[wav_file] = amplitude_envelope(signal, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "noverlap must be less than nperseg.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instrument \u001b[38;5;129;01min\u001b[39;00m all_instrument_classes:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m wav_file, (sample_rate, signal) \u001b[38;5;129;01min\u001b[39;00m instrument\u001b[38;5;241m.\u001b[39msignals_raw\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 70\u001b[0m         instrument\u001b[38;5;241m.\u001b[39msignals_envelope[wav_file] \u001b[38;5;241m=\u001b[39m \u001b[43mmel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 41\u001b[0m, in \u001b[0;36mmel_spectrogram\u001b[1;34m(signal, sample_rate, n_mels, n_fft, hop_length)\u001b[0m\n\u001b[0;32m     38\u001b[0m noverlap \u001b[38;5;241m=\u001b[39m n_fft \u001b[38;5;241m-\u001b[39m hop_length \u001b[38;5;28;01mif\u001b[39;00m hop_length \u001b[38;5;241m<\u001b[39m n_fft \u001b[38;5;28;01melse\u001b[39;00m n_fft \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Compute the Short-Time Fourier Transform (STFT)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m frequencies, times, spectrogram \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhann\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mnperseg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoverlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Compute power spectrogram (magnitude squared)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m power_spectrogram \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(spectrogram)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\popa4\\OneDrive\\Dokumenty\\GitHub\\USU-IRMAS-instrument-recognition\\.venv\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:1240\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, boundary, padded, axis, scaling)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scaling \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrum\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaling\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m not in [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrum\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsd\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1240\u001b[0m freqs, time, Zxx \u001b[38;5;241m=\u001b[39m \u001b[43m_spectral_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnperseg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoverlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_onesided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mboundary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpadded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m freqs, time, Zxx\n",
      "File \u001b[1;32mc:\\Users\\popa4\\OneDrive\\Dokumenty\\GitHub\\USU-IRMAS-instrument-recognition\\.venv\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:1851\u001b[0m, in \u001b[0;36m_spectral_helper\u001b[1;34m(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode, boundary, padded)\u001b[0m\n\u001b[0;32m   1849\u001b[0m     noverlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(noverlap)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m noverlap \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m nperseg:\n\u001b[1;32m-> 1851\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoverlap must be less than nperseg.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1852\u001b[0m nstep \u001b[38;5;241m=\u001b[39m nperseg \u001b[38;5;241m-\u001b[39m noverlap\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;66;03m# Padding occurs after boundary extension, so that the extended signal ends\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;66;03m# in zeros, instead of introducing an impulse at the end.\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;66;03m# I.e. if x = [..., 3, 2]\u001b[39;00m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# extend then pad -> [..., 3, 2, 2, 3, 0, 0, 0]\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;66;03m# pad then extend -> [..., 3, 2, 0, 0, 0, 2, 3]\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: noverlap must be less than nperseg."
     ]
    }
   ],
   "source": [
    "# spectrogram se počítá skrz FFT (fft = frekvence místo amplitudy, neural network mňamuje)\n",
    "'''\n",
    "Přes librosu to nejde, divný dependencies na starší verze numpy\n",
    "\n",
    "def mel_spectrogram(signal, sample_rate, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_mels=n_mels, \n",
    "                                                         n_fft=n_fft, hop_length=hop_length)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    return mel_spectrogram_db\n",
    "'''\n",
    "\n",
    "def hz_to_mel(hz):\n",
    "    return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "def mel_to_hz(mel):\n",
    "    return 700 * (10**(mel / 2595) - 1)\n",
    "\n",
    "def mel_filter_bank(sample_rate, n_fft, n_mels):\n",
    "    mel_min = 0\n",
    "    mel_max = hz_to_mel(sample_rate / 2)  # Nyquist frequency\n",
    "    mel_points = np.linspace(mel_min, mel_max, n_mels + 2)  # Equally spaced in Mel scale\n",
    "    hz_points = mel_to_hz(mel_points)  # Convert Mel points to Hz\n",
    "    bin_points = np.floor((n_fft + 1) * hz_points / sample_rate).astype(int)  # FFT bin numbers\n",
    "    \n",
    "    filter_bank = np.zeros((n_mels, n_fft // 2 + 1))\n",
    "    \n",
    "    for i in range(1, n_mels + 1):\n",
    "        filter_bank[i - 1, bin_points[i - 1]:bin_points[i]] = \\\n",
    "            (np.arange(bin_points[i - 1], bin_points[i]) - bin_points[i - 1]) / (bin_points[i] - bin_points[i - 1])\n",
    "        filter_bank[i - 1, bin_points[i]:bin_points[i + 1]] = \\\n",
    "            (bin_points[i + 1] - np.arange(bin_points[i], bin_points[i + 1])) / (bin_points[i + 1] - bin_points[i])\n",
    "    \n",
    "    return filter_bank\n",
    "\n",
    "def mel_spectrogram(signal, sample_rate, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    # Adjust the noverlap to be less than nperseg\n",
    "    noverlap = n_fft - hop_length if hop_length < n_fft else n_fft // 2\n",
    "    \n",
    "    # Compute the Short-Time Fourier Transform (STFT)\n",
    "    frequencies, times, spectrogram = scipy.signal.stft(signal, fs=sample_rate, window='hann',\n",
    "                                                        nperseg=n_fft, noverlap=noverlap, nfft=n_fft)\n",
    "    \n",
    "    # Compute power spectrogram (magnitude squared)\n",
    "    power_spectrogram = np.abs(spectrogram)**2\n",
    "    \n",
    "    # Create the Mel filter bank and apply it\n",
    "    mel_filter = mel_filter_bank(sample_rate, n_fft, n_mels)\n",
    "    mel_spectrogram = np.dot(mel_filter, power_spectrogram[:n_fft // 2 + 1])\n",
    "    \n",
    "    # Convert power to decibels (log scale)\n",
    "    mel_spectrogram_db = 10 * np.log10(mel_spectrogram + 1e-9)  # Add small value to avoid log(0)\n",
    "    \n",
    "    return mel_spectrogram_db, times\n",
    "\n",
    "\n",
    "def plot_mel_spectrogram(mel_spectrogram, times, sample_rate):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(mel_spectrogram, aspect='auto', origin='lower', cmap='coolwarm',\n",
    "               extent=[times.min(), times.max(), 0, sample_rate // 2])\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for instrument in all_instrument_classes:\n",
    "    for wav_file, (sample_rate, signal) in instrument.signals_raw.items():\n",
    "        instrument.signals_envelope[wav_file] = mel_spectrogram(signal, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "\n",
    "Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = signal\n",
    "# y_train = instrument\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='Leaky ReLU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
